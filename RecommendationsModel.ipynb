{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52bc3308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': b'4Z48C3WAYR', 'userId': b'5408'}\n",
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 4s 818ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 6.0006e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0022 - loss: 23813.1938 - regularization_loss: 0.0000e+00 - total_loss: 23813.1938\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 3s 803ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0047 - factorized_top_k/top_5_categorical_accuracy: 0.0505 - factorized_top_k/top_10_categorical_accuracy: 0.0658 - factorized_top_k/top_50_categorical_accuracy: 0.1606 - factorized_top_k/top_100_categorical_accuracy: 0.2398 - loss: 21729.4966 - regularization_loss: 0.0000e+00 - total_loss: 21729.4966  \n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 3s 753ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0655 - factorized_top_k/top_5_categorical_accuracy: 0.4365 - factorized_top_k/top_10_categorical_accuracy: 0.5396 - factorized_top_k/top_50_categorical_accuracy: 0.7459 - factorized_top_k/top_100_categorical_accuracy: 0.8618 - loss: 14131.8352 - regularization_loss: 0.0000e+00 - total_loss: 14131.8352\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 3s 734ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1938 - factorized_top_k/top_5_categorical_accuracy: 0.7611 - factorized_top_k/top_10_categorical_accuracy: 0.8122 - factorized_top_k/top_50_categorical_accuracy: 0.9132 - factorized_top_k/top_100_categorical_accuracy: 0.9352 - loss: 8529.6267 - regularization_loss: 0.0000e+00 - total_loss: 8529.6267\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 3s 789ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3668 - factorized_top_k/top_5_categorical_accuracy: 0.7855 - factorized_top_k/top_10_categorical_accuracy: 0.8303 - factorized_top_k/top_50_categorical_accuracy: 0.9267 - factorized_top_k/top_100_categorical_accuracy: 0.9494 - loss: 7459.4001 - regularization_loss: 0.0000e+00 - total_loss: 7459.4001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x127d614b910>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, Text\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "# creating a data frame\n",
    "recipes = pd.read_csv(\"recipes.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "\n",
    "recipes = recipes.astype({\"recipeId\": str})\n",
    "ratings = ratings.astype({\"userId\": str, \"recipeId\": str, \"rating\": str})\n",
    "\n",
    "newColumn = []\n",
    "\n",
    "\n",
    "# for i in recipes['categories']:\n",
    "#     temp = i.split(\" | \")\n",
    "#     newColumn.append(temp)\n",
    "\n",
    "# recipes.drop(columns=['categories'])\n",
    "# recipes[\"categories\"] = newColumn\n",
    "# print(recipes)\n",
    "\n",
    "# print(recipes.dtypes)\n",
    "\n",
    "recipes = tf.data.Dataset.from_tensor_slices(dict(recipes))\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings))\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"name\": x[\"name\"],\n",
    "    \"userId\": x[\"userId\"]\n",
    "})\n",
    "\n",
    "recipes = recipes.map(lambda x: x[\"name\"])\n",
    "                      \n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)\n",
    "\n",
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"userId\"]))\n",
    "\n",
    "recipe_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "recipe_titles_vocabulary.adapt(recipes)\n",
    "\n",
    "\n",
    "class RecipeModel(tfrs.Model):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      recipe_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_model = user_model\n",
    "    self.recipe_model = recipe_model\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    user_embeddings = self.user_model(features[\"userId\"])\n",
    "    positive_recipe_embeddings = self.recipe_model(features[\"name\"])\n",
    "    return self.task(user_embeddings, positive_recipe_embeddings)\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "recipe_model = tf.keras.Sequential([\n",
    "    recipe_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(recipe_titles_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    recipes.batch(128).map(recipe_model)\n",
    "  )\n",
    ")\n",
    "\n",
    "model = RecipeModel(user_model, recipe_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "model.fit(ratings.batch(4096), epochs=5)\n",
    "\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    recipes.batch(100).map(lambda title: (title, model.recipe_model(title))))\n",
    "\n",
    "# Get some recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6893975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations for user 10: [b'CFZG' b'WR' b'WR']\n"
     ]
    }
   ],
   "source": [
    "_, titles = index(np.array([\"10\"]))\n",
    "print(f\"Top 3 recommendations for user 10: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c478e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
